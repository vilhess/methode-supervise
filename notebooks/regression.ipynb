{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importation de quelques librairies\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chemin de nos données d'entrainement et de test\n",
    "\n",
    "train_path = '../data/data_reg/wine_train.csv' # replace with your path\n",
    "test_path = '../data/data_reg/wine_test.csv' # replace with your path\n",
    "\n",
    "# chargement des données\n",
    "\n",
    "df_train = pd.read_csv(train_path).drop('wine_ID', axis=1)\n",
    "df_test = pd.read_csv(test_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>wine_type</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.26</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.054</td>\n",
       "      <td>41.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.55</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.018</td>\n",
       "      <td>45.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.98936</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.34</td>\n",
       "      <td>12.9</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.9</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.99260</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.32</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.29</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0.044</td>\n",
       "      <td>33.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.99536</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.36</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.037</td>\n",
       "      <td>33.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.99230</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.49</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.2              0.16         0.26             7.1      0.054   \n",
       "1            7.3              0.22         0.31             2.3      0.018   \n",
       "2            8.9              0.13         0.49             1.0      0.028   \n",
       "3            6.0              0.17         0.29             9.7      0.044   \n",
       "4            7.5              0.19         0.34             2.6      0.037   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 41.0                 224.0  0.99660  3.38       0.55   \n",
       "1                 45.0                  80.0  0.98936  3.06       0.34   \n",
       "2                  6.0                  24.0  0.99260  2.91       0.32   \n",
       "3                 33.0                  98.0  0.99536  3.12       0.36   \n",
       "4                 33.0                 125.0  0.99230  3.10       0.49   \n",
       "\n",
       "   alcohol  wine_type  target  \n",
       "0     10.1          0       5  \n",
       "1     12.9          0       7  \n",
       "2      9.9          0       5  \n",
       "3      9.2          0       6  \n",
       "4     11.1          0       7  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualisation des données\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# informations sur les données\n",
    "\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description des données\n",
    "\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forme des données\n",
    "\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disrtibution des classes\n",
    "\n",
    "df_train['target'].hist()\n",
    "plt.title('Quality distribution')\n",
    "plt.xlabel('Quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de corrélation\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(df_train.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des variables\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "for i in range(len(df_train.columns)):\n",
    "    fig.add_subplot(5, 3, i+1)\n",
    "    sns.histplot(df_train.iloc[:, i], color='green', label=df_train.columns[i])\n",
    "    # show the mean and median\n",
    "    plt.axvline(df_train.iloc[:, i].mean(), linestyle='dashed', color='red', label='mean')\n",
    "    plt.axvline(df_train.iloc[:, i].median(), linestyle='dashed', color='blue', label='median')\n",
    "    plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation des données en train test\n",
    "\n",
    "X = df_train.drop('target', axis=1)\n",
    "y = df_train['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "# Entrainement du modèle\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction sur les données de test\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "# Evaluation du modèle\n",
    "\n",
    "print(f\"Le r2 vaut : {r2_score(y_test, y_preds)}\")\n",
    "\n",
    "# Sauvegarde des résultats pour streamlit\n",
    "\n",
    "new_results = pd.DataFrame({'y_test': y_test,\n",
    "                            'y_preds': y_preds})\n",
    "\n",
    "new_results.to_csv('../résultats_models/regression/linear_regression.csv', index=False)\n",
    "\n",
    "# soumission des résultats\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "y_preds = model.predict(df_test.drop('wine_ID', axis=1))\n",
    "\n",
    "submission = pd.DataFrame({'wine_ID': df_test['wine_ID'],\n",
    "                            'target': y_preds})\n",
    "\n",
    "submission.to_csv('../soumission/regression/linear_regression.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "model = CatBoostRegressor(iterations=10000, depth=10, learning_rate=0.1, loss_function='RMSE', eval_metric='R2', random_seed=42)\n",
    "\n",
    "# Entrainement du modèle\n",
    "\n",
    "model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=0)\n",
    "\n",
    "# Prédiction sur les données de test\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "# Evaluation du modèle\n",
    "\n",
    "print(f'Le r2 vaut : {r2_score(y_test, y_preds)}')\n",
    "\n",
    "# Sauvegarde des résultats pour streamlit\n",
    "\n",
    "new_results = pd.DataFrame({'y_test': y_test,\n",
    "                            'y_preds': y_preds})\n",
    "\n",
    "new_results.to_csv('../résultats_models/regression/catboost.csv', index=False)\n",
    "\n",
    "# soumission des résultats\n",
    "\n",
    "model = CatBoostRegressor(iterations=10000, depth=10, learning_rate=0.1, loss_function='RMSE', eval_metric='R2', random_seed=42)\n",
    "\n",
    "model.fit(X, y, verbose=0)\n",
    "\n",
    "y_preds = model.predict(df_test.drop('wine_ID', axis=1))\n",
    "\n",
    "submission = pd.DataFrame({'wine_ID': df_test['wine_ID'],\n",
    "                            'target': y_preds})\n",
    "\n",
    "submission.to_csv('../soumission/regression/catboost.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Définition de notre espaces de paramètres\n",
    "\n",
    "params = {'n_estimators': [100, 200, 300, 400, 500],\n",
    "            'max_depth': [5, 10, 15, 20, 25],\n",
    "            'min_samples_split': [2, 5, 10, 15, 20],\n",
    "            'min_samples_leaf': [1, 2, 5, 10, 15]}\n",
    "\n",
    "# Création de notre modèle\n",
    "\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Création de notre grille de recherche\n",
    "\n",
    "grid = GridSearchCV(model, params, cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Entrainement de notre modèle\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Affichage des meilleurs paramètres\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "\n",
    "# Prédiction sur les données de test\n",
    "\n",
    "y_preds = grid.predict(X_test)\n",
    "\n",
    "# Evaluation du modèle\n",
    "\n",
    "print(f'Le r2 vaut : {r2_score(y_test, y_preds)}')\n",
    "\n",
    "# Sauvegarde des résultats pour streamlit\n",
    "\n",
    "new_results = pd.DataFrame({'y_test': y_test,\n",
    "                            'y_preds': y_preds})\n",
    "\n",
    "new_results.to_csv('../résultats_models/regression/random_forest.csv', index=False)\n",
    "\n",
    "# soumission des résultats\n",
    "\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.set_params(**grid.best_params_)\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "y_preds = model.predict(df_test.drop('wine_ID', axis=1))\n",
    "\n",
    "submission = pd.DataFrame({'wine_ID': df_test['wine_ID'],\n",
    "                            'target': y_preds})\n",
    "\n",
    "submission.to_csv('../soumission/regression/random_forest.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = TensorDataset(torch.tensor(X_train.values, dtype=torch.float32), torch.tensor(y_train.values, dtype=torch.float32))\n",
    "testset = TensorDataset(torch.tensor(X_test.values, dtype=torch.float32), torch.tensor(y_test.values, dtype=torch.float32))\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "fullset = TensorDataset(torch.tensor(X.values, dtype=torch.float32), torch.tensor(y.values, dtype=torch.float32))\n",
    "fullloader = DataLoader(fullset, batch_size=32, shuffle=True)\n",
    "\n",
    "full_testset = TensorDataset(torch.tensor(df_test.drop('wine_ID', axis=1).values, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetworkRegressor, self).__init__()\n",
    "        self.fc1 = nn.Linear(12, 6)\n",
    "        self.fc2 = nn.Linear(6, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 : -6.790782354171641\n",
      "r2 : -1.3876904013280407\n",
      "r2 : -0.4537691809879181\n",
      "r2 : -0.11414973950713247\n",
      "r2 : 0.008500800546965337\n",
      "r2 : 0.05780434831522718\n",
      "r2 : 0.10949598764592106\n",
      "r2 : 0.13903718976330492\n",
      "r2 : 0.15699748173055839\n",
      "r2 : 0.1483217385602147\n",
      "r2 : 0.1776998590520894\n",
      "r2 : 0.20958914178555588\n",
      "r2 : 0.1590275784333739\n",
      "r2 : 0.22613270562681953\n",
      "r2 : 0.19869800479642608\n",
      "r2 : 0.2246869062930812\n",
      "r2 : 0.19012636080216572\n",
      "r2 : 0.19183292092352566\n",
      "r2 : 0.24565077270860025\n",
      "r2 : 0.21808677621820638\n",
      "r2 : 0.2386808983225175\n",
      "r2 : 0.25051748713609456\n",
      "r2 : 0.25580954008607093\n",
      "r2 : 0.2546438711415089\n",
      "r2 : 0.23062522802975882\n",
      "r2 : 0.2506549427236383\n",
      "r2 : 0.24285989181585121\n",
      "r2 : 0.2650106324105176\n",
      "r2 : 0.2566913490121274\n",
      "r2 : 0.25041184665544747\n",
      "r2 : 0.2403094111655527\n",
      "r2 : 0.2678987926068852\n",
      "r2 : 0.2633170306858298\n",
      "r2 : 0.1309500644410806\n",
      "r2 : 0.27317397908959795\n",
      "r2 : 0.26388070150804377\n",
      "r2 : 0.26793958383665684\n",
      "r2 : 0.23433618236627052\n",
      "r2 : 0.25866543857079694\n",
      "r2 : 0.1301889240616111\n",
      "r2 : 0.16242126247602795\n",
      "r2 : 0.2648808594972686\n",
      "r2 : 0.2559917160117573\n",
      "r2 : 0.27206402340589986\n",
      "r2 : 0.26253838439697197\n",
      "r2 : 0.13202485492533855\n",
      "r2 : 0.2668662918058723\n",
      "r2 : 0.2030748243922711\n",
      "r2 : 0.20133640164353317\n",
      "r2 : 0.21212757914001346\n",
      "r2 : 0.1553228067114073\n",
      "r2 : 0.24461087493394928\n",
      "r2 : 0.25516616218631505\n",
      "r2 : 0.2098809836543214\n",
      "r2 : 0.25879633771756805\n",
      "r2 : -0.05290346476551133\n",
      "r2 : 0.09562262744025485\n",
      "r2 : 0.27439587314757996\n",
      "r2 : 0.2616007376363715\n",
      "r2 : 0.2756137629214145\n",
      "r2 : 0.22743350421929276\n",
      "r2 : 0.2069949129968811\n",
      "r2 : 0.25981036098279553\n",
      "r2 : 0.22271618948542193\n",
      "r2 : 0.2758310233008653\n",
      "r2 : 0.27887624015841317\n",
      "r2 : 0.20770233951022132\n",
      "r2 : 0.281909100914725\n",
      "r2 : 0.2786101668413222\n",
      "r2 : 0.23331253567595545\n",
      "r2 : 0.27158859018561243\n",
      "r2 : 0.25881685682114264\n",
      "r2 : 0.2726141736655302\n",
      "r2 : 0.2743238239580986\n",
      "r2 : 0.26792042757291124\n",
      "r2 : 0.28054058858040065\n",
      "r2 : 0.279117737856012\n",
      "r2 : 0.2812326851354724\n",
      "r2 : 0.17970736670654874\n",
      "r2 : 0.2600627974559353\n",
      "r2 : 0.23797806933827814\n",
      "r2 : 0.2775003287048565\n",
      "r2 : 0.2781937128206411\n",
      "r2 : 0.23177938824886513\n",
      "r2 : 0.2684358705589639\n",
      "r2 : 0.2209904706521384\n",
      "r2 : 0.26880878887019766\n",
      "r2 : 0.2242148100111493\n",
      "r2 : 0.26341497802142666\n",
      "r2 : 0.19453282483283463\n",
      "r2 : 0.28087573493329865\n",
      "r2 : 0.27220695004680184\n",
      "r2 : 0.14320957771566722\n",
      "r2 : 0.2740500085738947\n",
      "r2 : 0.280557881737335\n",
      "r2 : 0.22225701182732283\n",
      "r2 : 0.23223018392939832\n",
      "r2 : 0.24518029830017563\n",
      "r2 : 0.2679845016233956\n",
      "r2 : 0.248975500527591\n",
      "r2 : 0.2790688074612532\n",
      "r2 : 0.19514868388354856\n",
      "r2 : 0.28030761904429236\n",
      "r2 : 0.2744215176699206\n",
      "r2 : 0.26854215957677663\n",
      "r2 : 0.27883220046658397\n",
      "r2 : 0.26868190073825193\n",
      "r2 : 0.2808317624437662\n",
      "r2 : 0.2745600788562529\n",
      "r2 : 0.26771827731511433\n",
      "r2 : 0.27451051297190243\n",
      "r2 : 0.24008083445750483\n",
      "r2 : 0.25206229177850503\n",
      "r2 : 0.19884757904861794\n",
      "r2 : 0.26682105701044867\n",
      "r2 : 0.27901437918140837\n",
      "r2 : 0.27847742671839715\n",
      "r2 : 0.2746778542644305\n",
      "r2 : 0.2813194802761134\n",
      "r2 : 0.16171075797290801\n",
      "r2 : 0.2816130152390012\n",
      "r2 : 0.2786122201722089\n",
      "r2 : 0.28200964453179767\n",
      "r2 : 0.2742515374303819\n",
      "r2 : 0.2764593436573509\n",
      "r2 : 0.2634683735559623\n",
      "r2 : 0.2812886673291326\n",
      "r2 : 0.22884127901181883\n",
      "r2 : 0.19553834675304838\n",
      "r2 : 0.22996349573419783\n",
      "r2 : 0.24901815014056794\n",
      "r2 : 0.256044593333717\n",
      "r2 : 0.24160013321763485\n",
      "r2 : 0.2343663894493635\n",
      "r2 : 0.27498229993565015\n",
      "r2 : 0.23742874705732153\n",
      "r2 : 0.27759697374335734\n",
      "r2 : 0.25958170515414647\n",
      "r2 : 0.2772183566967876\n",
      "r2 : 0.24831491768744163\n",
      "r2 : 0.2689929219806574\n",
      "r2 : 0.23407078453001773\n",
      "r2 : 0.2787967386571881\n",
      "r2 : 0.25598054746735144\n",
      "r2 : 0.27005183002936173\n",
      "r2 : 0.19579704914519525\n",
      "r2 : 0.28125511576484086\n",
      "r2 : 0.12005763001253889\n",
      "r2 : 0.26518885824748173\n",
      "r2 : 0.21939791135911524\n",
      "r2 : 0.23634904418323854\n",
      "r2 : 0.28302010369604536\n",
      "r2 : 0.2633102569415372\n",
      "r2 : 0.278779066657183\n",
      "r2 : 0.20187435684743238\n",
      "r2 : 0.26457360472979097\n",
      "r2 : 0.2675491125543379\n",
      "r2 : 0.13225043534937542\n",
      "r2 : 0.27434900487878633\n",
      "r2 : 0.2765351595869515\n",
      "r2 : 0.2666699251325173\n",
      "r2 : 0.25110413397899667\n",
      "r2 : 0.27437070944091557\n",
      "r2 : 0.2199832064231988\n",
      "r2 : 0.278122189548767\n",
      "r2 : 0.23957130665130089\n",
      "r2 : 0.20005431064185297\n",
      "r2 : 0.28197388171672777\n",
      "r2 : 0.15076963456560466\n",
      "r2 : 0.2697149383564935\n",
      "r2 : 0.23158290004062798\n",
      "r2 : 0.286285302177387\n",
      "r2 : 0.26539439793952146\n",
      "r2 : 0.17708495887701914\n",
      "r2 : 0.23882540690183274\n",
      "r2 : 0.23066825527431467\n",
      "r2 : 0.27535797269972695\n",
      "r2 : 0.1807498621212641\n",
      "r2 : 0.18772021778128145\n",
      "r2 : 0.21141220022274398\n",
      "r2 : 0.2716601185881825\n",
      "r2 : 0.2747693970658337\n",
      "r2 : 0.2775070514563245\n",
      "r2 : 0.27710412592674294\n",
      "r2 : 0.27325313989900857\n",
      "r2 : 0.17866282976636982\n",
      "r2 : 0.2657558518609986\n",
      "r2 : 0.2561574053425202\n",
      "r2 : 0.2834628247666944\n",
      "r2 : 0.26632563212556837\n",
      "r2 : 0.2802860055363483\n",
      "r2 : 0.2770960730680989\n",
      "r2 : 0.27587446493856815\n",
      "r2 : 0.22152674046674548\n",
      "r2 : 0.21905237281674128\n",
      "r2 : 0.2818018030268147\n",
      "r2 : 0.23855989551825274\n",
      "r2 : 0.28058328790122666\n",
      "r2 : 0.2614286248654625\n",
      "r2 : 0.2843177933536244\n",
      "r2 : 0.27276984849190034\n",
      "r2 : 0.18237581256695823\n",
      "r2 : 0.2776279068294336\n",
      "r2 : 0.2374370225886735\n",
      "r2 : 0.2804671875421928\n",
      "r2 : 0.21434445846813477\n",
      "r2 : 0.2740439161283639\n",
      "r2 : 0.25957153072405836\n",
      "r2 : 0.1743144380027848\n",
      "r2 : 0.2835303621421841\n",
      "r2 : 0.28415157802849667\n",
      "r2 : 0.26248269025747273\n",
      "r2 : 0.22663539163426327\n",
      "r2 : 0.2778368134789231\n",
      "r2 : 0.20255829623775656\n",
      "r2 : 0.2802606264447891\n",
      "r2 : 0.2655162027091189\n",
      "r2 : 0.2794289576486627\n",
      "r2 : 0.22439479895763725\n",
      "r2 : 0.2430077254283335\n",
      "r2 : 0.1813247131482837\n",
      "r2 : 0.2324540169678565\n",
      "r2 : 0.2804374824227356\n",
      "r2 : 0.27257159093748506\n",
      "r2 : 0.2038256953424521\n",
      "r2 : 0.2426002430017783\n",
      "r2 : 0.26291222279877524\n",
      "r2 : 0.27028561877599944\n",
      "r2 : 0.28413719883518196\n",
      "r2 : 0.21471109569865943\n",
      "r2 : 0.28397794729221904\n",
      "r2 : 0.26360757786323685\n",
      "r2 : 0.24775261899086332\n",
      "r2 : 0.27264069247484357\n",
      "r2 : 0.2701951324988937\n",
      "r2 : 0.2773544204136361\n",
      "r2 : 0.20770098835939732\n",
      "r2 : 0.24857149658986566\n",
      "r2 : 0.2807606885445634\n",
      "r2 : 0.19611735296522237\n",
      "r2 : 0.26737353329641544\n",
      "r2 : 0.2789118916831854\n",
      "r2 : 0.2736318553025531\n",
      "r2 : 0.2848678995416869\n",
      "r2 : 0.2258757069507179\n",
      "r2 : 0.2549860901368505\n",
      "r2 : 0.21710349280091756\n",
      "r2 : 0.23838173840435628\n",
      "r2 : 0.26979773778855953\n",
      "r2 : 0.2779201183351102\n",
      "r2 : 0.2878033917146644\n",
      "r2 : 0.26121266459500947\n",
      "r2 : 0.2737449828438727\n",
      "r2 : 0.28630214261042\n",
      "r2 : 0.2805233416814482\n",
      "r2 : 0.28553139846203235\n",
      "r2 : 0.2772650771648433\n",
      "r2 : 0.2658810709762801\n",
      "r2 : 0.2751627959001721\n",
      "r2 : 0.264563956500931\n",
      "r2 : 0.24705670630229026\n",
      "r2 : 0.27261792830084464\n",
      "r2 : 0.23284245210024934\n",
      "r2 : 0.27553239216997505\n",
      "r2 : 0.27450960404201974\n",
      "r2 : 0.2763111967369749\n",
      "r2 : 0.28399872944181137\n",
      "r2 : 0.2845663895039673\n",
      "r2 : 0.2832747800670139\n",
      "r2 : 0.24734100975496986\n",
      "r2 : 0.2567413225439852\n",
      "r2 : 0.28011806286197993\n",
      "r2 : 0.2841637715348654\n",
      "r2 : 0.24520668142506818\n",
      "r2 : 0.26862082398743814\n",
      "r2 : 0.2545109377543703\n",
      "r2 : 0.2767410340236969\n",
      "r2 : 0.2774860652297635\n",
      "r2 : 0.25542007733265104\n",
      "r2 : 0.2514175040411254\n",
      "r2 : 0.2622966996908719\n",
      "r2 : 0.19553981073010474\n",
      "r2 : 0.23350693184329419\n",
      "r2 : 0.27434182964666276\n",
      "r2 : 0.278078335260731\n",
      "r2 : 0.26021495221827873\n",
      "r2 : 0.2828511374551148\n",
      "r2 : 0.2644763041752334\n",
      "r2 : 0.2468451267789642\n",
      "r2 : 0.2890945136131561\n",
      "r2 : 0.24249644238898582\n",
      "r2 : 0.19086248838449382\n",
      "r2 : 0.28378744811523215\n",
      "r2 : 0.17113827987998043\n",
      "r2 : 0.24800125016397734\n",
      "r2 : 0.2876149488976816\n",
      "r2 : 0.27594924730346904\n",
      "r2 : 0.28248523916788826\n",
      "r2 : 0.2859379604589811\n",
      "r2 : 0.283170094794305\n",
      "r2 : 0.2860081446807353\n",
      "r2 : 0.2808826039747845\n",
      "r2 : 0.28587099569298935\n",
      "r2 : 0.2476580037094298\n",
      "r2 : 0.10828284538948496\n",
      "r2 : 0.284843718940643\n",
      "r2 : 0.28589386603939826\n",
      "r2 : 0.24043297778340966\n",
      "r2 : 0.04523925962102693\n",
      "r2 : 0.1954145980287455\n",
      "r2 : 0.28517904455123133\n",
      "r2 : 0.2529225080533627\n",
      "r2 : 0.27526355636851807\n",
      "r2 : 0.28460988027836387\n",
      "r2 : 0.2835683979407069\n",
      "r2 : 0.25216311657488144\n",
      "r2 : 0.2586011372417135\n",
      "r2 : 0.27644145869089276\n",
      "r2 : 0.28579363091183263\n",
      "r2 : 0.204689523981761\n",
      "r2 : 0.2855564865229192\n",
      "r2 : 0.1870296407296791\n",
      "r2 : 0.2810001596426619\n",
      "r2 : 0.2536606063907768\n",
      "r2 : 0.2829832142696531\n",
      "r2 : 0.27043667565280216\n",
      "r2 : 0.2712460556917986\n",
      "r2 : 0.28061806122155275\n",
      "r2 : 0.2775752258197616\n",
      "r2 : 0.2879594173838532\n",
      "r2 : 0.2805230192699977\n",
      "r2 : 0.2630077465955746\n",
      "r2 : 0.24731342108939924\n",
      "r2 : 0.27989550229115956\n",
      "r2 : 0.24853800908003043\n",
      "r2 : 0.2788321320898006\n",
      "r2 : 0.22481413483179902\n",
      "r2 : 0.27197287948347315\n",
      "r2 : 0.24164156800676773\n",
      "r2 : 0.2357158680488588\n",
      "r2 : 0.2844455197524587\n",
      "r2 : 0.2783830524992552\n",
      "r2 : 0.285351609035421\n",
      "r2 : 0.20044042792270844\n",
      "r2 : 0.28572324339626365\n",
      "r2 : 0.17766190180326558\n",
      "r2 : 0.28695272564163254\n",
      "r2 : 0.2314125468336542\n",
      "r2 : 0.2566696490015129\n",
      "r2 : 0.2804047074655228\n",
      "r2 : 0.26931446768696066\n",
      "r2 : 0.28258742922581015\n",
      "r2 : 0.2829847853939279\n",
      "r2 : 0.28266937596711517\n",
      "r2 : 0.23017133498882858\n",
      "r2 : 0.28699125441696516\n",
      "r2 : 0.2813345967050054\n",
      "r2 : 0.284924931435265\n",
      "r2 : 0.27283913342302235\n",
      "r2 : 0.24294799721602767\n",
      "r2 : 0.2806161609698903\n",
      "r2 : 0.26597766619469\n",
      "r2 : 0.19921856369666746\n",
      "r2 : 0.14882887415630885\n",
      "r2 : 0.28684996763844695\n",
      "r2 : 0.2872553684547535\n",
      "r2 : 0.257528496097159\n",
      "r2 : 0.2614138798880159\n",
      "r2 : 0.1994151619375566\n",
      "r2 : 0.2807949394968686\n",
      "r2 : 0.24566150085953675\n",
      "r2 : 0.2800961167552627\n",
      "r2 : 0.1810059264341407\n",
      "r2 : 0.248636841582769\n",
      "r2 : 0.19448574659203643\n",
      "r2 : 0.2759870868035986\n",
      "r2 : 0.257633199301446\n",
      "r2 : 0.27476341417307737\n",
      "r2 : 0.27116972619101365\n",
      "r2 : 0.22541287066378224\n",
      "r2 : 0.2413445294710751\n",
      "r2 : 0.20628913276371663\n",
      "r2 : 0.27423440516223996\n",
      "r2 : 0.2824450613896783\n",
      "r2 : 0.2777250477086355\n",
      "r2 : 0.2666118641783741\n",
      "r2 : 0.08249076467121497\n",
      "r2 : 0.2820049418734776\n",
      "r2 : 0.21533278623627428\n",
      "r2 : 0.23010512403264005\n",
      "r2 : 0.23059045416888357\n",
      "r2 : 0.22994806727704276\n",
      "r2 : 0.2601319092969193\n",
      "r2 : 0.24350421866800476\n",
      "r2 : 0.16594153280880097\n",
      "r2 : 0.2752538338301611\n",
      "r2 : 0.281132238073178\n",
      "r2 : 0.28086815554683553\n",
      "r2 : 0.27741092764570685\n",
      "r2 : 0.19946172673949514\n",
      "r2 : 0.2568488062715687\n",
      "r2 : 0.28498444739922657\n",
      "r2 : 0.22454256490227253\n",
      "r2 : 0.292138991588173\n",
      "r2 : 0.29535187960468956\n",
      "r2 : 0.2793258647924235\n",
      "r2 : 0.1619356254325226\n",
      "r2 : 0.22021029566829298\n",
      "r2 : 0.2890714205659357\n",
      "r2 : 0.30193014909743787\n",
      "r2 : 0.29867721588335394\n",
      "r2 : 0.2809203365341062\n",
      "r2 : 0.3084024295464981\n",
      "r2 : 0.3087549929619614\n",
      "r2 : 0.3131648630343433\n",
      "r2 : 0.2844896739110834\n",
      "r2 : 0.3089816655660509\n",
      "r2 : 0.2613000923978711\n",
      "r2 : 0.29179508590620484\n",
      "r2 : 0.294995747648618\n",
      "r2 : 0.30742704990022773\n",
      "r2 : 0.31625174038377335\n",
      "r2 : 0.31478075156967467\n",
      "r2 : 0.2998681365310022\n",
      "r2 : 0.31640381526744477\n",
      "r2 : 0.30237064643655487\n",
      "r2 : 0.282370513283816\n",
      "r2 : 0.284148419048192\n",
      "r2 : 0.30833714978953375\n",
      "r2 : 0.30902602314321626\n",
      "r2 : 0.30850069730213037\n",
      "r2 : 0.307059173047904\n",
      "r2 : 0.307717782271249\n",
      "r2 : 0.3061253404046813\n",
      "r2 : 0.2796991145752984\n",
      "r2 : 0.21377104308079953\n",
      "r2 : 0.3118104716087299\n",
      "r2 : 0.3070054208437828\n",
      "r2 : 0.31846262090953403\n",
      "r2 : 0.2815819818914749\n",
      "r2 : 0.30839564590769863\n",
      "r2 : 0.26745196751724987\n",
      "r2 : 0.31402794750797713\n",
      "r2 : 0.29653307485367086\n",
      "r2 : 0.27281748910821113\n",
      "r2 : 0.31332604257278995\n",
      "r2 : 0.2779037172541735\n",
      "r2 : 0.27164028772794857\n",
      "r2 : 0.3188256920473651\n",
      "r2 : 0.31337949996897707\n",
      "r2 : 0.3173221069776013\n",
      "r2 : 0.2833457645981913\n",
      "r2 : 0.2879287579726384\n",
      "r2 : 0.3181666871768679\n",
      "r2 : 0.26034952064008376\n",
      "r2 : 0.31050165386977513\n",
      "r2 : 0.27377860642042395\n",
      "r2 : 0.24710940463139863\n",
      "r2 : 0.2139930601434098\n",
      "r2 : 0.3181672702454672\n",
      "r2 : 0.31446935982122703\n",
      "r2 : 0.31397012529046453\n",
      "r2 : 0.322291091389293\n",
      "r2 : 0.3042338117247131\n",
      "r2 : 0.3175195524397235\n",
      "r2 : 0.32101635300398035\n",
      "r2 : 0.3099860131997879\n",
      "r2 : 0.3089310874207355\n",
      "r2 : 0.26354082663012\n",
      "r2 : 0.2835201501343576\n",
      "r2 : 0.32053262422470197\n",
      "r2 : 0.32290602130805157\n",
      "r2 : 0.32257444832017734\n",
      "r2 : 0.30894246466641206\n",
      "r2 : 0.32251342370375635\n",
      "r2 : 0.32505608467941194\n",
      "r2 : 0.3234270831058772\n",
      "r2 : 0.2985623922103333\n",
      "r2 : 0.2872179351981582\n",
      "r2 : 0.3227542551519528\n",
      "r2 : 0.313618798739255\n",
      "r2 : 0.3266456435410876\n",
      "r2 : 0.2981057313355684\n",
      "r2 : 0.3191899693919479\n",
      "r2 : 0.3215053893050881\n",
      "r2 : 0.3208606020710484\n",
      "r2 : 0.32509350717811125\n",
      "r2 : 0.32260458430129335\n",
      "r2 : 0.3233218881479777\n",
      "r2 : 0.3153371871110231\n",
      "r2 : 0.29345333714766353\n",
      "r2 : 0.32469616421210024\n",
      "r2 : 0.2729725613973022\n",
      "r2 : 0.25573161023141333\n",
      "r2 : 0.3299878891683159\n",
      "r2 : 0.31624074884022024\n",
      "r2 : 0.3284749592322208\n",
      "r2 : 0.2779181867744811\n",
      "r2 : 0.3256462438515557\n",
      "r2 : 0.3291855761788294\n",
      "r2 : 0.32494841699277477\n",
      "r2 : 0.3066720654876539\n",
      "r2 : 0.327690372687763\n",
      "r2 : 0.2912377692960063\n",
      "r2 : 0.33196751100776534\n",
      "r2 : 0.3238281410856043\n",
      "r2 : 0.32598584554897647\n",
      "r2 : 0.31927785399629105\n",
      "r2 : 0.278975983109782\n",
      "r2 : 0.3313365444045422\n",
      "r2 : 0.25987401970059887\n",
      "r2 : 0.309578928621439\n",
      "r2 : 0.3088988792446066\n",
      "r2 : 0.3251693906235912\n",
      "r2 : 0.3263352033296334\n",
      "r2 : 0.3205752653455357\n",
      "r2 : 0.3309795948931903\n",
      "r2 : 0.24850571827728907\n",
      "r2 : 0.33167860370308255\n",
      "r2 : 0.3299668031356193\n",
      "r2 : 0.3206485434102059\n",
      "r2 : 0.3069787021645023\n",
      "r2 : 0.26787300748795084\n",
      "r2 : 0.320066121709111\n",
      "r2 : 0.3247635253200749\n",
      "r2 : 0.24144882809677015\n",
      "r2 : 0.23487764891768892\n",
      "r2 : 0.3154253175249364\n",
      "r2 : 0.3152780262469823\n",
      "r2 : 0.3216699193144934\n",
      "r2 : 0.29630842970933746\n",
      "r2 : 0.3106724913451444\n",
      "r2 : 0.31093322027391934\n",
      "r2 : 0.32663530112101236\n",
      "r2 : 0.31569383480685875\n",
      "r2 : 0.33196349090410726\n",
      "r2 : 0.1912646327006292\n",
      "r2 : 0.3332859272958769\n",
      "r2 : 0.30643216153669517\n",
      "r2 : 0.3226983458010647\n",
      "r2 : 0.3204782692823409\n",
      "r2 : 0.32926900854415087\n",
      "r2 : 0.3210871458085093\n",
      "r2 : 0.2896016686155287\n",
      "r2 : 0.32480470211258594\n",
      "r2 : 0.33405083051172424\n",
      "r2 : 0.2884172025287782\n",
      "r2 : 0.30494254142992316\n",
      "r2 : 0.31690274884813385\n",
      "r2 : 0.3178928941764412\n",
      "r2 : 0.33381835524736747\n",
      "r2 : 0.30138111143302504\n",
      "r2 : 0.3346250546901207\n",
      "r2 : 0.21918888723511687\n",
      "r2 : 0.3319437580496708\n",
      "r2 : 0.32913897046034113\n",
      "r2 : 0.33279897837578476\n",
      "r2 : 0.3207501497578946\n",
      "r2 : 0.3092916313679629\n",
      "r2 : 0.3180275976463419\n",
      "r2 : 0.31466180412194866\n",
      "r2 : 0.32370536676181527\n",
      "r2 : 0.33396776242133397\n",
      "r2 : 0.3317572174260368\n",
      "r2 : 0.33125021903060203\n",
      "r2 : 0.3210188546167426\n",
      "r2 : 0.32374545226895124\n",
      "r2 : 0.3336736786278546\n",
      "r2 : 0.3142719951125974\n",
      "r2 : 0.331876879254819\n",
      "r2 : 0.30314457380349635\n",
      "r2 : 0.25914208210343126\n",
      "r2 : 0.2742534905627946\n",
      "r2 : 0.2714427898929411\n",
      "r2 : 0.33107165495061985\n",
      "r2 : 0.3036067892461355\n",
      "r2 : 0.33410832500087473\n",
      "r2 : 0.33136270543077595\n",
      "r2 : 0.321152809299615\n",
      "r2 : 0.23572011367851275\n",
      "r2 : 0.336144197523356\n",
      "r2 : 0.2844503704275322\n",
      "r2 : 0.3012355991763279\n",
      "r2 : 0.3120201330308665\n",
      "r2 : 0.30334374362007244\n",
      "r2 : 0.30295779418531255\n",
      "r2 : 0.32173094486377607\n",
      "r2 : 0.2510302015089053\n",
      "r2 : 0.3316221280741217\n",
      "r2 : 0.3109648356107556\n",
      "r2 : 0.3330100150515162\n",
      "r2 : 0.33073576042289643\n",
      "r2 : 0.32613728462167757\n",
      "r2 : 0.3342834254288053\n",
      "r2 : 0.334946341285725\n",
      "r2 : 0.2683794216257791\n",
      "r2 : 0.2963816128584955\n",
      "r2 : 0.3253599724853151\n",
      "r2 : 0.26647361651575907\n",
      "r2 : 0.3227197346653423\n",
      "r2 : 0.3256390625780653\n",
      "r2 : 0.31128930675119704\n",
      "r2 : 0.3037603494315312\n",
      "r2 : 0.31715594436129657\n",
      "r2 : 0.30699708953698057\n",
      "r2 : 0.33478236158608254\n",
      "r2 : 0.33346920669642477\n",
      "r2 : 0.2852202855568562\n",
      "r2 : 0.32999856826984986\n",
      "r2 : 0.21698659618155003\n",
      "r2 : 0.330686108603399\n",
      "r2 : 0.09962388514074416\n",
      "r2 : 0.2838280783838848\n",
      "r2 : 0.3081046966869284\n",
      "r2 : 0.29570435173920895\n",
      "r2 : 0.3043286974455439\n",
      "r2 : 0.3306635673837268\n",
      "r2 : 0.29335279326891683\n",
      "r2 : 0.3329608153495378\n",
      "r2 : 0.332201338402065\n",
      "r2 : 0.3314870192155699\n",
      "r2 : 0.25982739771635566\n",
      "r2 : 0.3333149345979235\n",
      "r2 : 0.30831543912158177\n",
      "r2 : 0.3333330247217593\n",
      "r2 : 0.31801896273088226\n",
      "r2 : 0.282292212215169\n",
      "r2 : 0.3305362655659083\n",
      "r2 : 0.2733909956588346\n",
      "r2 : 0.3359968065858474\n",
      "r2 : 0.3179516559156286\n",
      "r2 : 0.3356186402429423\n",
      "r2 : 0.33635689519660905\n",
      "r2 : 0.3304929589338055\n",
      "r2 : 0.24334223797667376\n",
      "r2 : 0.33346361277043757\n",
      "r2 : 0.24565869033509125\n",
      "r2 : 0.26963343109636806\n",
      "r2 : 0.324652301734353\n",
      "r2 : 0.30806252052798233\n",
      "r2 : 0.32836788783823545\n",
      "r2 : 0.31418817993303616\n",
      "r2 : 0.30456295069141304\n",
      "r2 : 0.3238770737079856\n",
      "r2 : 0.32288064855362786\n",
      "r2 : 0.33845545406536237\n",
      "r2 : 0.30331064601799385\n",
      "r2 : 0.3360582692095594\n",
      "r2 : 0.331633738215129\n",
      "r2 : 0.3285507447767383\n",
      "r2 : 0.32559754392953366\n",
      "r2 : 0.33597220796682803\n",
      "r2 : 0.3273251845520201\n",
      "r2 : 0.32136233242942636\n",
      "r2 : 0.3105043592595915\n",
      "r2 : 0.2729047935450889\n",
      "r2 : 0.3359198327128996\n",
      "r2 : 0.3382436374468474\n",
      "r2 : 0.33250445252781435\n",
      "r2 : 0.33086841118130095\n",
      "r2 : 0.34052576330313367\n",
      "r2 : 0.32632064450630904\n",
      "r2 : 0.33891326761203466\n",
      "r2 : 0.29798627499177865\n",
      "r2 : 0.277621894417721\n",
      "r2 : 0.33657424461168517\n",
      "r2 : 0.3168442307445014\n",
      "r2 : 0.33611110965768465\n",
      "r2 : 0.28335658107204564\n",
      "r2 : 0.33391845964955513\n",
      "r2 : 0.30751830251202694\n",
      "r2 : 0.3294310543836474\n",
      "r2 : 0.3226399548878709\n",
      "r2 : 0.3073040644723093\n",
      "r2 : 0.28495866152862614\n",
      "r2 : 0.328551477779609\n",
      "r2 : 0.3340784953953245\n",
      "r2 : 0.23191691059921027\n",
      "r2 : 0.3131620114808198\n",
      "r2 : 0.27115069229090927\n",
      "r2 : 0.2386422692773148\n",
      "r2 : 0.33786704081903396\n",
      "r2 : 0.33060315253758865\n",
      "r2 : 0.3214211905034229\n",
      "r2 : 0.3002606504668057\n",
      "r2 : 0.31610560310228986\n",
      "r2 : 0.3332068960166794\n",
      "r2 : 0.33185150648516937\n",
      "r2 : 0.3362150857202726\n",
      "r2 : 0.33443630629336507\n",
      "r2 : 0.3290092897211986\n",
      "r2 : 0.32855124842797256\n",
      "r2 : 0.34066862637404216\n",
      "r2 : 0.16957946035553007\n",
      "r2 : 0.3399305116426258\n",
      "r2 : 0.33472501130381116\n",
      "r2 : 0.3204810407605674\n",
      "r2 : 0.2741408806642919\n",
      "r2 : 0.33667702134197774\n",
      "r2 : 0.33004079766821093\n",
      "r2 : 0.30320324972083923\n",
      "r2 : 0.28176485421260966\n",
      "r2 : 0.2441878253828481\n",
      "r2 : 0.2980645262763024\n",
      "r2 : 0.3377460144929103\n",
      "r2 : 0.3392794961737844\n",
      "r2 : 0.17777793924215513\n",
      "r2 : 0.32859924837364973\n",
      "r2 : 0.31591464297706595\n",
      "r2 : 0.30595566315979195\n",
      "r2 : 0.32310799121837463\n",
      "r2 : 0.3353267068912634\n",
      "r2 : 0.34004466962130697\n",
      "r2 : 0.3278274318743277\n",
      "r2 : 0.31727902502869154\n",
      "r2 : 0.30889433512489195\n",
      "r2 : 0.2540860190442893\n",
      "r2 : 0.33693130033477214\n",
      "r2 : 0.3288917973428026\n",
      "r2 : 0.32988581058468003\n",
      "r2 : 0.2536523134730949\n",
      "r2 : 0.33734548964778543\n",
      "r2 : 0.3347745204844359\n",
      "r2 : 0.33622685332155355\n",
      "r2 : 0.3071643109078914\n",
      "r2 : 0.34017660316597653\n",
      "r2 : 0.3405756576981066\n",
      "r2 : 0.3357665565999103\n",
      "r2 : 0.3125081542840399\n",
      "r2 : 0.3212683780202218\n",
      "r2 : 0.32574794494167225\n",
      "r2 : 0.3196731610671404\n",
      "r2 : 0.322764980988834\n",
      "r2 : 0.2875260289688779\n",
      "r2 : 0.3389036070599486\n",
      "r2 : 0.22727373435272014\n",
      "r2 : 0.33754600716873806\n",
      "r2 : 0.21598142881047977\n",
      "r2 : 0.3314698757774569\n",
      "r2 : 0.3431118936280695\n",
      "r2 : 0.21908459344441056\n",
      "r2 : 0.34299135888597043\n",
      "r2 : 0.33726646982032293\n",
      "r2 : 0.3060765799374353\n",
      "r2 : 0.23321632740228282\n",
      "r2 : 0.3299565999149029\n",
      "r2 : 0.3212821135765874\n",
      "r2 : 0.3370765241635487\n",
      "r2 : 0.3347247452664729\n",
      "r2 : 0.30677294581197934\n",
      "r2 : 0.31608570536901637\n",
      "r2 : 0.2862209077421478\n",
      "r2 : 0.33858544887029884\n",
      "r2 : 0.30377318993363434\n",
      "r2 : 0.3162386300147435\n",
      "r2 : 0.3407275883848573\n",
      "r2 : 0.2685535359774107\n",
      "r2 : 0.33724263497463636\n",
      "r2 : 0.3329936713074497\n",
      "r2 : 0.33089273418096543\n",
      "r2 : 0.3348339011010165\n",
      "r2 : 0.3159585045221244\n",
      "r2 : 0.3380185058029139\n",
      "r2 : 0.33277220194228196\n",
      "r2 : 0.3228705377337311\n",
      "r2 : 0.3327915069581948\n",
      "r2 : 0.2358102479692099\n",
      "r2 : 0.19716619884552156\n",
      "r2 : 0.33815792364519126\n",
      "r2 : 0.32271812063576333\n",
      "r2 : 0.3380701584478605\n",
      "r2 : 0.3148875408004146\n",
      "r2 : 0.30074496529378114\n",
      "r2 : 0.3285003201637\n",
      "r2 : 0.33648435161590773\n",
      "r2 : 0.33317560795269296\n",
      "r2 : 0.33859472110686195\n",
      "r2 : 0.3262846766914591\n",
      "r2 : 0.3305060658610338\n",
      "r2 : 0.3316976684068573\n",
      "r2 : 0.33855979117481483\n",
      "r2 : 0.339291965177837\n",
      "r2 : 0.2869378132860696\n",
      "r2 : 0.3058447521039678\n",
      "r2 : 0.30052176308136147\n",
      "r2 : 0.3329945718941867\n",
      "r2 : 0.33103987123954093\n",
      "r2 : 0.3380542348758828\n",
      "r2 : 0.3264308794320784\n",
      "r2 : 0.33182575887737675\n",
      "r2 : 0.3361668517090468\n",
      "r2 : 0.30153045476265095\n",
      "r2 : 0.33726158931849826\n",
      "r2 : 0.3199585416096572\n",
      "r2 : 0.3342274428848626\n",
      "r2 : 0.3360108835632326\n",
      "r2 : 0.28490936215357465\n",
      "r2 : 0.3079197049139131\n",
      "r2 : 0.2893831342873808\n",
      "r2 : 0.32145189944725205\n",
      "r2 : 0.3372344134314176\n",
      "r2 : 0.32746847802316825\n",
      "r2 : 0.33556385617270446\n",
      "r2 : 0.27647878884462873\n",
      "r2 : 0.30479142546126925\n",
      "r2 : 0.31722922596400205\n",
      "r2 : 0.3287043980695554\n",
      "r2 : 0.336035322562524\n",
      "r2 : 0.30349833809365856\n",
      "r2 : 0.3381413552374377\n",
      "r2 : 0.3387954070562792\n",
      "r2 : 0.3230395063410625\n",
      "r2 : 0.337638943063728\n",
      "r2 : 0.28559674904468235\n",
      "r2 : 0.333378088371722\n",
      "r2 : 0.28947633129845607\n",
      "r2 : 0.2833315297906932\n",
      "r2 : 0.3263396437029322\n",
      "r2 : 0.2394621522781356\n",
      "r2 : 0.3085113123580777\n",
      "r2 : 0.3358317180854048\n",
      "r2 : 0.3386896164210844\n",
      "r2 : 0.2773636400201369\n",
      "r2 : 0.3217509420519823\n",
      "r2 : 0.33732651690743676\n",
      "r2 : 0.32869415640484956\n",
      "r2 : 0.3375074380728179\n",
      "r2 : 0.3262756516416755\n",
      "r2 : 0.3343045477184948\n",
      "r2 : 0.33458765607942753\n",
      "r2 : 0.332912932704269\n",
      "r2 : 0.3327271358245274\n",
      "r2 : 0.33130933735412327\n",
      "r2 : 0.3339394061205264\n",
      "r2 : 0.1914382019230566\n",
      "r2 : 0.32963186684063484\n",
      "r2 : 0.30775665018297693\n",
      "r2 : 0.3364773369346321\n",
      "r2 : 0.2861325503415122\n",
      "r2 : 0.3328440626452742\n",
      "r2 : 0.33481350722889547\n",
      "r2 : 0.32179188675767245\n",
      "r2 : 0.2845151704465988\n",
      "r2 : 0.32758677496198596\n",
      "r2 : 0.3173316904288599\n",
      "r2 : 0.3191070351033787\n",
      "r2 : 0.33618880537203266\n",
      "r2 : 0.3339143046294999\n",
      "r2 : 0.3186327836931744\n",
      "r2 : 0.3354407105727416\n",
      "r2 : 0.30936557826894995\n",
      "r2 : 0.3325655467870252\n",
      "r2 : 0.32721784821803823\n",
      "r2 : 0.308656601333663\n",
      "r2 : 0.3324635154187705\n",
      "r2 : 0.3152160744214686\n",
      "r2 : 0.2707958575389591\n",
      "r2 : 0.3375346382437897\n",
      "r2 : 0.3304857884039961\n",
      "r2 : 0.3312203920362591\n",
      "r2 : 0.33629076438702044\n",
      "r2 : 0.32951610716905144\n",
      "r2 : 0.32899632954714464\n",
      "r2 : 0.3354483784573369\n",
      "r2 : 0.3226429748905839\n",
      "r2 : 0.3297449240058813\n",
      "r2 : 0.32287189010817663\n",
      "r2 : 0.3351892743019905\n",
      "r2 : 0.33159402673038607\n",
      "r2 : 0.3341300491839938\n",
      "r2 : 0.3175969515988112\n",
      "r2 : 0.3041743513645745\n",
      "r2 : 0.2520422102942905\n",
      "r2 : 0.3247181794151437\n",
      "r2 : 0.30293243808784587\n",
      "r2 : 0.3226413963755239\n",
      "r2 : 0.2675261102757197\n",
      "r2 : 0.32526131855048923\n",
      "r2 : 0.3318189254710925\n",
      "r2 : 0.3324184471211089\n",
      "r2 : 0.33679825309296985\n",
      "r2 : 0.31876533471907054\n",
      "r2 : 0.33597961126877995\n",
      "r2 : 0.3337821043215182\n",
      "r2 : 0.33271284360225295\n",
      "r2 : 0.33433636074025175\n",
      "r2 : 0.30441648166227686\n",
      "r2 : 0.31538174052228385\n",
      "r2 : 0.3082730502345512\n",
      "r2 : 0.3287125554258199\n",
      "r2 : 0.20148106663143728\n",
      "r2 : 0.28315095448955996\n",
      "r2 : 0.33759631078473207\n",
      "r2 : 0.3335486535023465\n",
      "r2 : 0.28818817075218195\n",
      "r2 : 0.33360591289942265\n",
      "r2 : 0.33210820940667773\n",
      "r2 : 0.33820629018337056\n",
      "r2 : 0.3277569820932429\n",
      "r2 : 0.30600620050547944\n",
      "r2 : 0.3365523365794387\n",
      "r2 : 0.30968194297420115\n",
      "r2 : 0.33327899030239194\n",
      "r2 : 0.33415411784436067\n",
      "r2 : 0.3214173228867958\n",
      "r2 : 0.33412640792136594\n",
      "r2 : 0.33527303750778203\n",
      "r2 : 0.3162370862682048\n",
      "r2 : 0.3372159526534755\n",
      "r2 : 0.3393359842932725\n",
      "r2 : 0.32238742053318725\n",
      "r2 : 0.3394345065871295\n",
      "r2 : 0.2982093174884275\n",
      "r2 : 0.31451087598952854\n",
      "r2 : 0.3239655975799183\n",
      "r2 : 0.32956017009453553\n",
      "r2 : 0.29992904646578067\n",
      "r2 : 0.3058165717592538\n",
      "r2 : 0.3381891304989274\n",
      "r2 : 0.2785917544937395\n",
      "r2 : 0.30197204468653205\n",
      "r2 : 0.33222115085527715\n",
      "r2 : 0.33999238957913547\n",
      "r2 : 0.3379644585200988\n",
      "r2 : 0.2954552636144635\n",
      "r2 : 0.31628088502513607\n",
      "r2 : 0.2962058647278125\n",
      "r2 : 0.33337658163403483\n",
      "r2 : 0.30212858818159616\n",
      "r2 : 0.31902907318655105\n",
      "r2 : 0.3319881132110589\n",
      "r2 : 0.2586913309745965\n",
      "r2 : 0.3284848824854969\n",
      "r2 : 0.3346841002216324\n",
      "r2 : 0.3177419147729793\n",
      "r2 : 0.31125695944004317\n",
      "r2 : 0.32803240301953274\n",
      "r2 : 0.28024977265250806\n",
      "r2 : 0.3204990976316823\n",
      "r2 : 0.3165989283737284\n",
      "r2 : 0.334165491776965\n",
      "r2 : 0.30681282182283265\n",
      "r2 : 0.33833171911896864\n",
      "r2 : 0.33683096972916804\n",
      "r2 : 0.3235673082865498\n",
      "r2 : 0.32024683590478986\n",
      "r2 : 0.3335376990740867\n",
      "r2 : 0.3359893830125956\n",
      "r2 : 0.3406286041109543\n",
      "r2 : 0.340157314337564\n",
      "r2 : 0.3238298669190045\n",
      "r2 : 0.3414433066930114\n",
      "r2 : 0.3398024855854491\n",
      "r2 : 0.3440788791197611\n",
      "r2 : 0.33977904681091675\n",
      "r2 : 0.33372650959790706\n",
      "r2 : 0.33692805238054435\n",
      "r2 : 0.32000717918766375\n",
      "r2 : 0.3410257729563433\n",
      "r2 : 0.2991751658421712\n",
      "r2 : 0.30200604175845924\n",
      "r2 : 0.3378334466651155\n",
      "r2 : 0.3429068579975071\n",
      "r2 : 0.2861783664019001\n",
      "r2 : 0.31943837656150875\n",
      "r2 : 0.33872979343854037\n",
      "r2 : 0.3383555636516211\n",
      "r2 : 0.3340658610013204\n",
      "r2 : 0.33890580162435346\n",
      "r2 : 0.34131699258855197\n",
      "r2 : 0.3413821785480924\n",
      "r2 : 0.2992442053577896\n",
      "r2 : 0.340576934842188\n",
      "r2 : 0.21497161432424516\n",
      "r2 : 0.3388765931986266\n",
      "r2 : 0.2961991203022578\n",
      "r2 : 0.31200637311501855\n",
      "r2 : 0.31526562291800275\n",
      "r2 : 0.30179394388516356\n",
      "r2 : 0.3174158391687071\n",
      "r2 : 0.3421041982493057\n",
      "r2 : 0.2711114446672829\n",
      "r2 : 0.3317678576150467\n",
      "r2 : 0.3237323307139275\n",
      "r2 : 0.3197581774077517\n",
      "r2 : 0.31262905750628645\n",
      "r2 : 0.30793696668055337\n",
      "r2 : 0.34398478354669837\n",
      "r2 : 0.3392529110380105\n",
      "r2 : 0.3428175608933556\n",
      "r2 : 0.30088908558229144\n",
      "r2 : 0.24304308745142322\n",
      "r2 : 0.34329902852892724\n",
      "r2 : 0.30324147474569896\n",
      "r2 : 0.33224210926553843\n",
      "r2 : 0.32055194041897117\n",
      "r2 : 0.34328762917240363\n",
      "r2 : 0.3385034383987001\n",
      "r2 : 0.3430431958686321\n",
      "r2 : 0.3377603755388746\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetworkRegressor()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for inputs, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.view(-1), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        y_preds = []\n",
    "        for inputs, labels in testset:\n",
    "            outputs = model(inputs)\n",
    "            y_preds.append(outputs.item())\n",
    "    print(f\"r2 : {r2_score(y_test, y_preds)}\")\n",
    "\n",
    "\n",
    "new_results = pd.DataFrame({'y_test': y_test,\n",
    "                            'y_preds': y_preds})\n",
    "\n",
    "new_results.to_csv('../résultats_models/regression/neural_network.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for epoch 0 : 226.27088533383665\n",
      "for epoch 1 : 10.66029664400582\n",
      "for epoch 2 : 7.673589160509199\n",
      "for epoch 3 : 6.182035192150936\n",
      "for epoch 4 : 4.756762839923395\n",
      "for epoch 5 : 3.8318470003448915\n",
      "for epoch 6 : 3.10766361138531\n",
      "for epoch 7 : 2.526102371304949\n",
      "for epoch 8 : 2.07741824377363\n",
      "for epoch 9 : 1.7230226508924895\n",
      "for epoch 10 : 1.4591853691038685\n",
      "for epoch 11 : 1.2800033228976704\n",
      "for epoch 12 : 1.1582391766187186\n",
      "for epoch 13 : 1.0787443357093311\n",
      "for epoch 14 : 1.025876410653658\n",
      "for epoch 15 : 0.9907247468689891\n",
      "for epoch 16 : 0.9700071831172872\n",
      "for epoch 17 : 0.9523125168319061\n",
      "for epoch 18 : 0.9490960089959831\n",
      "for epoch 19 : 0.9260405065300309\n",
      "for epoch 20 : 0.9140349537412696\n",
      "for epoch 21 : 0.9182342622324685\n",
      "for epoch 22 : 0.89075149433844\n",
      "for epoch 23 : 0.8865977099565702\n",
      "for epoch 24 : 0.8825172846005341\n",
      "for epoch 25 : 0.870323657989502\n",
      "for epoch 26 : 0.8557440256961039\n",
      "for epoch 27 : 0.848980707821445\n",
      "for epoch 28 : 0.8534191459695869\n",
      "for epoch 29 : 0.8269616124507423\n",
      "for epoch 30 : 0.8197836483193335\n",
      "for epoch 31 : 0.8097049873844485\n",
      "for epoch 32 : 0.802736052982161\n",
      "for epoch 33 : 0.7996873295752802\n",
      "for epoch 34 : 0.7967998697378925\n",
      "for epoch 35 : 0.7915824306345431\n",
      "for epoch 36 : 0.787275510135098\n",
      "for epoch 37 : 0.7833010359345195\n",
      "for epoch 38 : 0.7857419742602054\n",
      "for epoch 39 : 0.7793273548378008\n",
      "for epoch 40 : 0.7647216598564219\n",
      "for epoch 41 : 0.7617498022095065\n",
      "for epoch 42 : 0.7571442559639984\n",
      "for epoch 43 : 0.7561226370178651\n",
      "for epoch 44 : 0.7721926210639632\n",
      "for epoch 45 : 0.7565839120717807\n",
      "for epoch 46 : 0.7568272151679636\n",
      "for epoch 47 : 0.7596832505453412\n",
      "for epoch 48 : 0.7630491344449676\n",
      "for epoch 49 : 0.7530620742902577\n",
      "for epoch 50 : 0.7481216506980289\n",
      "for epoch 51 : 0.7460482594008758\n",
      "for epoch 52 : 0.7359310781287256\n",
      "for epoch 53 : 0.7414843896839106\n",
      "for epoch 54 : 0.7326373758717118\n",
      "for epoch 55 : 0.7302262717596838\n",
      "for epoch 56 : 0.7281727877175697\n",
      "for epoch 57 : 0.7214843356442229\n",
      "for epoch 58 : 0.712335497384595\n",
      "for epoch 59 : 0.7287399892773584\n",
      "for epoch 60 : 0.7256067509406081\n",
      "for epoch 61 : 0.7158836013524332\n",
      "for epoch 62 : 0.7229869362906874\n",
      "for epoch 63 : 0.7204577475786209\n",
      "for epoch 64 : 0.714450018845986\n",
      "for epoch 65 : 0.7143307139522561\n",
      "for epoch 66 : 0.7066045303211034\n",
      "for epoch 67 : 0.7109345512412418\n",
      "for epoch 68 : 0.7063917685822348\n",
      "for epoch 69 : 0.7027842077974961\n",
      "for epoch 70 : 0.7149994764651093\n",
      "for epoch 71 : 0.7028426289836937\n",
      "for epoch 72 : 0.7065847351729313\n",
      "for epoch 73 : 0.7067143412950997\n",
      "for epoch 74 : 0.7140242593171441\n",
      "for epoch 75 : 0.6988830648571531\n",
      "for epoch 76 : 0.7033441509598883\n",
      "for epoch 77 : 0.6993071434096755\n",
      "for epoch 78 : 0.7006368521496514\n",
      "for epoch 79 : 0.7180855893921629\n",
      "for epoch 80 : 0.7104799409057493\n",
      "for epoch 81 : 0.7051396357400395\n",
      "for epoch 82 : 0.7012960600240208\n",
      "for epoch 83 : 0.6996740616649111\n",
      "for epoch 84 : 0.6930934804900785\n",
      "for epoch 85 : 0.6958802835406545\n",
      "for epoch 86 : 0.7032347235167138\n",
      "for epoch 87 : 0.6967457752918529\n",
      "for epoch 88 : 0.6977994533203472\n",
      "for epoch 89 : 0.6962637033000171\n",
      "for epoch 90 : 0.6988962175690125\n",
      "for epoch 91 : 0.6942442473128577\n",
      "for epoch 92 : 0.6949909961669245\n",
      "for epoch 93 : 0.6971849964879383\n",
      "for epoch 94 : 0.7240214851972099\n",
      "for epoch 95 : 0.7052341822151825\n",
      "for epoch 96 : 0.6969353358879268\n",
      "for epoch 97 : 0.6920456742154104\n",
      "for epoch 98 : 0.7092701252375808\n",
      "for epoch 99 : 0.7015751888540304\n",
      "for epoch 100 : 0.7005329751801268\n",
      "for epoch 101 : 0.7017681697540195\n",
      "for epoch 102 : 0.6940328228139432\n",
      "for epoch 103 : 0.6895940525927277\n",
      "for epoch 104 : 0.6944688260555267\n",
      "for epoch 105 : 0.6961710881964068\n",
      "for epoch 106 : 0.7013022375998096\n",
      "for epoch 107 : 0.6929701796480429\n",
      "for epoch 108 : 0.6924743127321529\n",
      "for epoch 109 : 0.6943812519311905\n",
      "for epoch 110 : 0.6873788612189694\n",
      "for epoch 111 : 0.6922708163473094\n",
      "for epoch 112 : 0.6932713436397994\n",
      "for epoch 113 : 0.7001133294967569\n",
      "for epoch 114 : 0.6920315328045427\n",
      "for epoch 115 : 0.7060706813201726\n",
      "for epoch 116 : 0.6964768164347266\n",
      "for epoch 117 : 0.6998329831060962\n",
      "for epoch 118 : 0.690862460531921\n",
      "for epoch 119 : 0.6930460101254633\n",
      "for epoch 120 : 0.6931736796537292\n",
      "for epoch 121 : 0.6999021669693082\n",
      "for epoch 122 : 0.6968569039741409\n",
      "for epoch 123 : 0.6847514127180955\n",
      "for epoch 124 : 0.6997777683155559\n",
      "for epoch 125 : 0.7016077909235642\n",
      "for epoch 126 : 0.6933274661826196\n",
      "for epoch 127 : 0.6959536705061654\n",
      "for epoch 128 : 0.6962916773056316\n",
      "for epoch 129 : 0.6977370719764834\n",
      "for epoch 130 : 0.7129026294868683\n",
      "for epoch 131 : 0.6967728281628653\n",
      "for epoch 132 : 0.6907448050017669\n",
      "for epoch 133 : 0.6930072311764566\n",
      "for epoch 134 : 0.6969611914219144\n",
      "for epoch 135 : 0.6875679027811389\n",
      "for epoch 136 : 0.692630739273312\n",
      "for epoch 137 : 0.6972806612464869\n",
      "for epoch 138 : 0.7166177179211768\n",
      "for epoch 139 : 0.6994158000311005\n",
      "for epoch 140 : 0.6898051358271982\n",
      "for epoch 141 : 0.6879367154335307\n",
      "for epoch 142 : 0.695916746821359\n",
      "for epoch 143 : 0.6995103206032904\n",
      "for epoch 144 : 0.6908639989723669\n",
      "for epoch 145 : 0.6864878047849531\n",
      "for epoch 146 : 0.6956518849479818\n",
      "for epoch 147 : 0.7053647999451539\n",
      "for epoch 148 : 0.704701801744577\n",
      "for epoch 149 : 0.6860614447532413\n",
      "for epoch 150 : 0.6885779328713907\n",
      "for epoch 151 : 0.6815785253159353\n",
      "for epoch 152 : 0.6826839965080547\n",
      "for epoch 153 : 0.6872293338458114\n",
      "for epoch 154 : 0.6922873751582387\n",
      "for epoch 155 : 0.6991822978603506\n",
      "for epoch 156 : 0.6858445474199045\n",
      "for epoch 157 : 0.7029385729649357\n",
      "for epoch 158 : 0.6897985229146815\n",
      "for epoch 159 : 0.6900215953867012\n",
      "for epoch 160 : 0.6873103395522198\n",
      "for epoch 161 : 0.6917250354156316\n",
      "for epoch 162 : 0.691353866012297\n",
      "for epoch 163 : 0.6857774070350924\n",
      "for epoch 164 : 0.6883255865807846\n",
      "for epoch 165 : 0.696826202011554\n",
      "for epoch 166 : 0.6863984235814798\n",
      "for epoch 167 : 0.688682950406431\n",
      "for epoch 168 : 0.6907457707223491\n",
      "for epoch 169 : 0.6872096758022487\n",
      "for epoch 170 : 0.6881002086066754\n",
      "for epoch 171 : 0.6875651595748473\n",
      "for epoch 172 : 0.6864748473200842\n",
      "for epoch 173 : 0.6949924868400966\n",
      "for epoch 174 : 0.6865070474760555\n",
      "for epoch 175 : 0.6877007290512045\n",
      "for epoch 176 : 0.689691091530791\n",
      "for epoch 177 : 0.6942268459596367\n",
      "for epoch 178 : 0.6964279867221261\n",
      "for epoch 179 : 0.6885623962522667\n",
      "for epoch 180 : 0.6896704645635926\n",
      "for epoch 181 : 0.7078791019793983\n",
      "for epoch 182 : 0.6806725707148837\n",
      "for epoch 183 : 0.6949369503515903\n",
      "for epoch 184 : 0.6847393353965795\n",
      "for epoch 185 : 0.688581052923871\n",
      "for epoch 186 : 0.6818624608149039\n",
      "for epoch 187 : 0.6906177028317317\n",
      "for epoch 188 : 0.6930088449582875\n",
      "for epoch 189 : 0.6922232316476162\n",
      "for epoch 190 : 0.6986315250396729\n",
      "for epoch 191 : 0.6898084894240459\n",
      "for epoch 192 : 0.6808710185306095\n",
      "for epoch 193 : 0.6844750314115364\n",
      "for epoch 194 : 0.6835283742886837\n",
      "for epoch 195 : 0.6852363121008205\n",
      "for epoch 196 : 0.6920474590820687\n",
      "for epoch 197 : 0.7015199831155973\n",
      "for epoch 198 : 0.6847611359346693\n",
      "for epoch 199 : 0.7007826268672943\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetworkRegressor()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for inputs, labels in fullloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.view(-1), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "\n",
    "    print(f\"for epoch {epoch} : {running_loss / len(trainloader)}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    y_preds = []\n",
    "    for inputs in full_testset:\n",
    "        outputs = model(inputs[0])\n",
    "        y_preds.append(outputs.item())\n",
    "\n",
    "submission = pd.DataFrame({'wine_ID': df_test['wine_ID'],\n",
    "                            'target': y_preds})\n",
    "\n",
    "submission.to_csv('../soumission/regression/neural_network.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "df_train_scaled = scaler.fit_transform(df_train.drop('target', axis=1))\n",
    "df_test_scaled = scaler.transform(df_test.drop('wine_ID', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "# Entrainement du modèle\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prédiction sur les données de test\n",
    "\n",
    "y_preds = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation du modèle\n",
    "\n",
    "print(f\"Le r2 vaut : {r2_score(y_test, y_preds)}\")\n",
    "\n",
    "# Sauvegarde des résultats pour streamlit\n",
    "\n",
    "new_results = pd.DataFrame({'y_test': y_test,\n",
    "                            'y_preds': y_preds})\n",
    "\n",
    "new_results.to_csv('../résultats_models/regression/linear_regression_scaled.csv', index=False)\n",
    "\n",
    "# soumission des résultats\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(df_train_scaled, y)\n",
    "\n",
    "y_preds = model.predict(df_test_scaled)\n",
    "\n",
    "submission = pd.DataFrame({'wine_ID': df_test['wine_ID'],\n",
    "                            'target': y_preds})\n",
    "\n",
    "submission.to_csv('../soumission/regression/linear_regression_scaled.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(iterations=10000, depth=10, learning_rate=0.1, loss_function='RMSE', eval_metric='R2', random_seed=42)\n",
    "\n",
    "# Entrainement du modèle\n",
    "\n",
    "model.fit(X_train_scaled, y_train, eval_set=(X_test_scaled, y_test), verbose=0)\n",
    "\n",
    "# Prédiction sur les données de test\n",
    "\n",
    "y_preds = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation du modèle\n",
    "\n",
    "print(f'Le r2 vaut : {r2_score(y_test, y_preds)}')\n",
    "\n",
    "# Sauvegarde des résultats pour streamlit\n",
    "\n",
    "new_results = pd.DataFrame({'y_test': y_test,\n",
    "                            'y_preds': y_preds})\n",
    "\n",
    "new_results.to_csv('../résultats_models/regression/catboost_scaled.csv', index=False)\n",
    "\n",
    "# soumission des résultats\n",
    "\n",
    "model = CatBoostRegressor(iterations=10000, depth=10, learning_rate=0.1, loss_function='RMSE', eval_metric='R2', random_seed=42)\n",
    "\n",
    "model.fit(df_train_scaled, y, verbose=0)\n",
    "\n",
    "y_preds = model.predict(df_test_scaled)\n",
    "\n",
    "submission = pd.DataFrame({'wine_ID': df_test['wine_ID'],\n",
    "                            'target': y_preds})\n",
    "\n",
    "submission.to_csv('../soumission/regression/catboost_scaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Définition de notre espaces de paramètres\n",
    "\n",
    "params = {'n_estimators': [100, 200, 300, 400, 500],\n",
    "            'max_depth': [5, 10, 15, 20, 25],\n",
    "            'min_samples_split': [2, 5, 10, 15, 20],\n",
    "            'min_samples_leaf': [1, 2, 5, 10, 15]}\n",
    "\n",
    "# Création de notre grille de recherche\n",
    "\n",
    "grid = GridSearchCV(model, params, cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Entrainement de notre modèle\n",
    "\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Affichage des meilleurs paramètres\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "\n",
    "# Prédiction sur les données de test\n",
    "\n",
    "y_preds = grid.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation du modèle\n",
    "\n",
    "print(f'Le r2 vaut : {r2_score(y_test, y_preds)}')\n",
    "\n",
    "# Sauvegarde des résultats pour streamlit\n",
    "\n",
    "new_results = pd.DataFrame({'y_test': y_test,\n",
    "                            'y_preds': y_preds})\n",
    "\n",
    "new_results.to_csv('../résultats_models/regression/random_forest_scaled.csv', index=False)\n",
    "\n",
    "# soumission des résultats\n",
    "\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.set_params(**grid.best_params_)\n",
    "\n",
    "model.fit(df_train_scaled, y)\n",
    "\n",
    "y_preds = model.predict(df_test_scaled)\n",
    "\n",
    "submission = pd.DataFrame({'wine_ID': df_test['wine_ID'],\n",
    "                            'target': y_preds})\n",
    "\n",
    "submission.to_csv('../soumission/regression/random_forest_scaled.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comme un problème de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.8127186\ttest: 1.8109653\tbest: 1.8109653 (0)\ttotal: 26.5ms\tremaining: 13.2s\n",
      "10:\tlearn: 1.2483650\ttest: 1.2763464\tbest: 1.2763464 (10)\ttotal: 259ms\tremaining: 11.5s\n",
      "20:\tlearn: 1.0474611\ttest: 1.1227839\tbest: 1.1227839 (20)\ttotal: 490ms\tremaining: 11.2s\n",
      "30:\tlearn: 0.9365666\ttest: 1.0505099\tbest: 1.0505099 (30)\ttotal: 774ms\tremaining: 11.7s\n",
      "40:\tlearn: 0.8613896\ttest: 1.0110389\tbest: 1.0110389 (40)\ttotal: 1s\tremaining: 11.2s\n",
      "50:\tlearn: 0.8054991\ttest: 0.9846950\tbest: 0.9846950 (50)\ttotal: 1.24s\tremaining: 10.9s\n",
      "60:\tlearn: 0.7577790\ttest: 0.9680404\tbest: 0.9680404 (60)\ttotal: 1.47s\tremaining: 10.6s\n",
      "70:\tlearn: 0.7157625\ttest: 0.9557640\tbest: 0.9557640 (70)\ttotal: 1.71s\tremaining: 10.3s\n",
      "80:\tlearn: 0.6745259\ttest: 0.9459211\tbest: 0.9459211 (80)\ttotal: 1.94s\tremaining: 10s\n",
      "90:\tlearn: 0.6385105\ttest: 0.9360519\tbest: 0.9360519 (90)\ttotal: 2.18s\tremaining: 9.8s\n",
      "100:\tlearn: 0.6075732\ttest: 0.9316307\tbest: 0.9316307 (100)\ttotal: 2.41s\tremaining: 9.51s\n",
      "110:\tlearn: 0.5815233\ttest: 0.9257934\tbest: 0.9257934 (110)\ttotal: 2.64s\tremaining: 9.24s\n",
      "120:\tlearn: 0.5543865\ttest: 0.9223646\tbest: 0.9223185 (119)\ttotal: 2.87s\tremaining: 9s\n",
      "130:\tlearn: 0.5254638\ttest: 0.9189364\tbest: 0.9187869 (128)\ttotal: 3.1s\tremaining: 8.73s\n",
      "140:\tlearn: 0.5015847\ttest: 0.9146459\tbest: 0.9144947 (139)\ttotal: 3.33s\tremaining: 8.49s\n",
      "150:\tlearn: 0.4773570\ttest: 0.9097881\tbest: 0.9097881 (150)\ttotal: 3.57s\tremaining: 8.25s\n",
      "160:\tlearn: 0.4555742\ttest: 0.9071317\tbest: 0.9069648 (159)\ttotal: 3.8s\tremaining: 8s\n",
      "170:\tlearn: 0.4358398\ttest: 0.9041039\tbest: 0.9041039 (170)\ttotal: 4.03s\tremaining: 7.75s\n",
      "180:\tlearn: 0.4164884\ttest: 0.9018516\tbest: 0.9018516 (180)\ttotal: 4.26s\tremaining: 7.5s\n",
      "190:\tlearn: 0.3984182\ttest: 0.8990201\tbest: 0.8990201 (190)\ttotal: 4.48s\tremaining: 7.25s\n",
      "200:\tlearn: 0.3831997\ttest: 0.8980955\tbest: 0.8980955 (200)\ttotal: 4.71s\tremaining: 7.01s\n",
      "210:\tlearn: 0.3681870\ttest: 0.8962084\tbest: 0.8962084 (210)\ttotal: 4.95s\tremaining: 6.77s\n",
      "220:\tlearn: 0.3527065\ttest: 0.8951410\tbest: 0.8951410 (220)\ttotal: 5.18s\tremaining: 6.55s\n",
      "230:\tlearn: 0.3410962\ttest: 0.8949158\tbest: 0.8945745 (224)\ttotal: 5.42s\tremaining: 6.31s\n",
      "240:\tlearn: 0.3277269\ttest: 0.8930883\tbest: 0.8930883 (240)\ttotal: 5.69s\tremaining: 6.11s\n",
      "250:\tlearn: 0.3153120\ttest: 0.8921503\tbest: 0.8916931 (248)\ttotal: 5.93s\tremaining: 5.88s\n",
      "260:\tlearn: 0.3045774\ttest: 0.8909805\tbest: 0.8909805 (260)\ttotal: 6.17s\tremaining: 5.65s\n",
      "270:\tlearn: 0.2933267\ttest: 0.8909912\tbest: 0.8909250 (268)\ttotal: 6.42s\tremaining: 5.42s\n",
      "280:\tlearn: 0.2829221\ttest: 0.8906882\tbest: 0.8904227 (272)\ttotal: 6.66s\tremaining: 5.19s\n",
      "290:\tlearn: 0.2724724\ttest: 0.8906096\tbest: 0.8904227 (272)\ttotal: 6.89s\tremaining: 4.95s\n",
      "300:\tlearn: 0.2635075\ttest: 0.8906838\tbest: 0.8904147 (291)\ttotal: 7.12s\tremaining: 4.71s\n",
      "310:\tlearn: 0.2551697\ttest: 0.8906569\tbest: 0.8903050 (307)\ttotal: 7.36s\tremaining: 4.47s\n",
      "320:\tlearn: 0.2478253\ttest: 0.8904927\tbest: 0.8903050 (307)\ttotal: 7.6s\tremaining: 4.24s\n",
      "330:\tlearn: 0.2409555\ttest: 0.8907267\tbest: 0.8903050 (307)\ttotal: 7.84s\tremaining: 4s\n",
      "340:\tlearn: 0.2327724\ttest: 0.8916926\tbest: 0.8903050 (307)\ttotal: 8.09s\tremaining: 3.77s\n",
      "350:\tlearn: 0.2254170\ttest: 0.8908230\tbest: 0.8903050 (307)\ttotal: 8.33s\tremaining: 3.54s\n",
      "360:\tlearn: 0.2192005\ttest: 0.8908660\tbest: 0.8903050 (307)\ttotal: 8.54s\tremaining: 3.29s\n",
      "370:\tlearn: 0.2121431\ttest: 0.8909445\tbest: 0.8903050 (307)\ttotal: 8.78s\tremaining: 3.05s\n",
      "380:\tlearn: 0.2062201\ttest: 0.8919381\tbest: 0.8903050 (307)\ttotal: 9.04s\tremaining: 2.82s\n",
      "390:\tlearn: 0.2004145\ttest: 0.8923770\tbest: 0.8903050 (307)\ttotal: 9.27s\tremaining: 2.58s\n",
      "400:\tlearn: 0.1960586\ttest: 0.8922493\tbest: 0.8903050 (307)\ttotal: 9.51s\tremaining: 2.35s\n",
      "410:\tlearn: 0.1910965\ttest: 0.8934061\tbest: 0.8903050 (307)\ttotal: 9.74s\tremaining: 2.11s\n",
      "420:\tlearn: 0.1857515\ttest: 0.8931963\tbest: 0.8903050 (307)\ttotal: 9.96s\tremaining: 1.87s\n",
      "430:\tlearn: 0.1805907\ttest: 0.8939766\tbest: 0.8903050 (307)\ttotal: 10.2s\tremaining: 1.63s\n",
      "440:\tlearn: 0.1762580\ttest: 0.8945465\tbest: 0.8903050 (307)\ttotal: 10.4s\tremaining: 1.39s\n",
      "450:\tlearn: 0.1713408\ttest: 0.8958496\tbest: 0.8903050 (307)\ttotal: 10.7s\tremaining: 1.16s\n",
      "460:\tlearn: 0.1669171\ttest: 0.8959916\tbest: 0.8903050 (307)\ttotal: 10.9s\tremaining: 921ms\n",
      "470:\tlearn: 0.1617539\ttest: 0.8966664\tbest: 0.8903050 (307)\ttotal: 11.1s\tremaining: 684ms\n",
      "480:\tlearn: 0.1576055\ttest: 0.8975802\tbest: 0.8903050 (307)\ttotal: 11.3s\tremaining: 448ms\n",
      "490:\tlearn: 0.1538496\ttest: 0.8980232\tbest: 0.8903050 (307)\ttotal: 11.6s\tremaining: 212ms\n",
      "499:\tlearn: 0.1505930\ttest: 0.8981535\tbest: 0.8903050 (307)\ttotal: 11.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8903050098\n",
      "bestIteration = 307\n",
      "\n",
      "Shrink model to first 308 iterations.\n",
      "Le r2 vaut : 0.3393527836822734\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model = CatBoostClassifier(iterations=500, depth=10, learning_rate=0.1,  random_seed=42)\n",
    "\n",
    "# Entrainement du modèle\n",
    "\n",
    "model.fit(X_train_scaled, y_train, eval_set=(X_test_scaled, y_test), verbose=10)\n",
    "\n",
    "# Prédiction sur les données de test\n",
    "\n",
    "y_preds = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation du modèle\n",
    "\n",
    "print(f'Le r2 vaut : {r2_score(y_test, y_preds)}')\n",
    "\n",
    "# Sauvegarde des résultats pour streamlit\n",
    "\n",
    "new_results = pd.DataFrame({'y_test': y_test,\n",
    "                            'y_preds': y_preds.ravel()})\n",
    "\n",
    "new_results.to_csv('../résultats_models/regression/catboost_cla_scaled.csv', index=False)\n",
    "\n",
    "# soumission des résultats\n",
    "\n",
    "model = CatBoostClassifier(iterations=500, depth=10, learning_rate=0.1, random_seed=42)\n",
    "\n",
    "model.fit(df_train_scaled, y, verbose=0)\n",
    "\n",
    "y_preds = model.predict(df_test_scaled)\n",
    "\n",
    "submission = pd.DataFrame({'wine_ID': df_test['wine_ID'],\n",
    "                            'target': y_preds.ravel()})\n",
    "\n",
    "submission.to_csv('../soumission/regression/catboost_cla_scaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "970b6e94afd843568256675086d87407db15a8cd9814ea6ad86d69153853824c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
